---
category: "[[Clippings]]"
author: "[[XiaoHu.AI学院]]"
title: "采访当今最伟大的数学家对AI的看法 陶哲轩：我们正踏入数学的全新领域"
source: https://xiaohu.ai/p/14455
clipped: 2024-10-10
published: 
topics: 
tags: [clippings]
---

陶哲轩（Terence Tao），加州大学洛杉矶分校（UCLA）的数学教授，被誉为“数学界的莫扎特”，他被广泛认为是当今世界上最伟大的数学家。他已经获得了众多奖项，包括数学界的诺贝尔奖级别的奖项，因其在数学上的突破性成果。

尽管，当前的人工智能远未达到他的水平。但科技公司正在努力让AI赶上这一高度。

最近几代引人注目的AI——即使是强大的ChatGPT——都没有被设计来处理数学推理。相反，它们主要专注于语言：当你问它一个基础问题时，它并不会理解并执行一个方程或证明，而是根据可能的词语顺序给出答案。例如，最初的ChatGPT无法进行加法或乘法，但因为它看过足够多的代数例子，能解出x + 2 = 4这样的方程：“要解这个方程，首先从两边减去2……”

然而，OpenAI 现在明确推出了一系列新的“推理模型”，统称为 o1 系列，强调它们能够“像人一样”解决问题，处理复杂的数学和科学任务。如果这些模型成功了，它们可能会为陶和他的同行所从事的那种缓慢而孤独的工作带来巨大的变化。

在看到陶哲轩在网络上发表他对 o1 的看法后——他将其比作“**一个平庸但不完全无能的研究生**”——我希望进一步了解他对这项技术潜力的看法。上周通过 Zoom 进行的采访中，他描述了一种以前从未可能的 AI 驱动的“工业规模数学”。这种数学将在短期内仍然是由人类主导的核心工作，AI 只是作为数学家的假设和方法的润滑剂。人类和机器有着截然不同的优势，应被视为互补而非竞争关系。

---

***以下对话已为了篇幅和清晰度进行了编辑。***

**Matteo Wong**: 你第一次接触ChatGPT是什么时候？

**Terence Tao**: 几乎是它刚推出时我就试了一下。我给它出了一些难题，但它的答案很愚蠢。虽然语句通顺，使用了正确的术语，但几乎没有深度。对于真正高深的问题，早期的 GPT 根本不行。它们更适合一些有趣的事情——比如你可以要求它用诗歌或儿童故事的形式解释某个数学主题，这些真的很令人印象深刻。

**Wong**: OpenAI 说 o1 能“推理”，但你将其比作“一个平庸但不完全无能的研究生”。

**Tao**: 这个措辞最初被广泛传播，但也被误解了。我并不是说这个工具在研究生学习的每个方面都相当于一个研究生。我对这些工具作为研究助手的潜力感兴趣。研究项目有很多繁琐的步骤：你可能有一个想法，想要通过计算将其展开，但必须亲自动手完成所有计算。

**Wong**: 那么，它是一个平庸的研究助手？

**Tao**: 是的，它在充当这种助手时表现平庸。但我设想了一个未来，在这个未来中，你可以通过与聊天机器人对话来进行研究。你有一个想法，机器人会跟随你的思路并填补所有细节。

在某些领域，这已经在发生了。AI 多年前就征服了国际象棋，但国际象棋仍然蓬勃发展，因为现在一个技术不错的棋手可以推测在某些情况下哪些走法是好的，并使用国际象棋引擎查看20步后的结果。我认为这种情况最终会发生在数学领域：你有一个项目，然后问，“如果我尝试这个方法会怎么样？” 而不是花费数小时甚至数天去实际尝试，你可以指导 GPT 为你做这些事情。

使用 o1，您已经可以部分实现这一点。我给了它一个我知道怎么解的问题，尝试引导它。首先，我给了它一个提示，但它没理会，选择了别的办法，结果失败了。当我解释这一点后，它道歉并表示“好的，我会按照你的方式做。” 然后它合理地执行了我的指示，但又遇到了瓶颈，我不得不再次纠正它。模型从未找出最巧妙的步骤，它只会完成所有常规步骤，但缺乏想象力。

研究生和AI之间的一个关键区别是，研究生会学习。你告诉AI它的方式行不通，它会道歉，可能会暂时修正路线，但有时它又会回到之前的方法。如果你重新开始一个AI对话，一切又从头开始。我对研究生更有耐心，因为即使他们完全失败了，他们也有学习和自我纠正的潜力。

**Wong**: OpenAI 描述 o1 能够识别其错误，但你说这与持续学习不同，而持续学习正是使得错误对人类有意义的原因。

**Tao**: 是的，人类会成长。这些模型是静态的——我对 GPT-4 提供的反馈可能成为 GPT-5 训练数据的0.00001%。但这与对学生的反馈方式完全不同。

AI 和人类在学习和解决问题的方式上截然不同——我认为最好将AI视为完成任务的补充方式。在许多任务中，人类和AI分工不同会更具前景。

**Wong**: 你曾提到计算机程序可能会改变数学并使得人类之间的协作变得更容易。能详细解释一下吗？生成式AI在这方面能贡献什么？

**Tao**: 严格来说，这些程序不算AI，但证明助手是有用的计算机工具，它们能够检查数学论证是否正确。它们使大规模的数学合作成为可能，这是最近才出现的。

数学非常脆弱：如果证明中的某一步出错，整个论证可能会崩溃。如果你要进行一个有100人的协作项目，你需要将证明分成100个部分，每个人贡献一部分。但如果他们彼此不协调，这些部分可能无法正确衔接。因此，很少能看到超过五个人参与的项目。

使用证明助手，你不需要完全信任你的合作者，因为程序能够提供100%的保证。然后你可以进行像工厂生产一样的大规模数学生产，这在目前还不存在。一个人只专注于证明某种类型的结果，就像现代的供应链一样。

问题是这些程序非常挑剔。你必须用一种专门的语言来撰写你的论证，不能直接用英语。AI可能可以在从人类语言到这些程序语言的翻译上发挥作用。而翻译语言几乎正是大型语言模型擅长的事情。理想的情况是，你只需与聊天机器人对话，解释你的证明，机器人会将其转化为证明系统语言。

**Wong**: 所以聊天机器人并不是知识或创意的来源，而是一种接口？

**Tao**: 是的，它可能是非常有用的粘合剂。

**Wong**: 这种工具可能有助于解决哪些问题？

**Tao**: 传统的数学观念是，你挑选一些非常困难的问题，然后有一两个人花上七年时间，闭门造车地不断尝试。而你希望用AI解决的数学问题则是相反的。将最难的数学问题交给AI处理，这可能不会非常成功，毕竟我们已经有人类在攻克这些问题。

我最感兴趣的是尚不存在的数学领域。我刚启动的一个项目涉及一个叫做“普遍代数”的数学领域，研究某些数学陈述或方程是否会推导出其他陈述。过去，人们的研究方法是挑选一两个方程并深入研究，就像工匠一个一个制作玩具一样，然后再去研究下一个。现在我们有工厂，可以一次生产成千上万个玩具。在我的项目中，有大约4000个方程，任务是发现它们的联系。每一个都相对容易，但有数百万个可能的推导关系。这就像是有10个光点——10个已经被相对深入研究的方程——而其余部分则是一片未知领域。

有些领域已经经历了这种转变，比如基因组学。过去，如果你想测序某个生物体的基因组，这可能会是一个完整的博士论文。现在我们有基因测序机器，遗传学家们可以测序整个群体的基因。你可以用这种方式开展不同类型的基因研究。相对狭窄而深入的数学研究，比如专家花很多时间研究一个问题，可以被大规模协作的、更广泛但可能较浅的AI辅助问题研究所取代。这可能是一种非常互补的数学洞见方式。

**Wong**: 这让我想起谷歌DeepMind开发的一个AI程序AlphaFold，它能够预测蛋白质的三维结构，而这曾是一个需要一个一个解决的问题。

**Tao**: 对，但这并不意味着蛋白质科学已经过时了。你必须改变研究的方向。150年前，数学家们的主要任务是解偏微分方程。现在有计算机包能自动完成这些。600年前，数学家们建立了正弦和余弦的表格，这些曾是航海所必需的，而现在计算机可以在几秒钟内生成这些表格。

我对重复人类已经擅长的事情并不感兴趣。这看起来效率低下。我认为在前沿领域，人类和AI将始终是必需的。它们有互补的优势。AI擅长将数十亿条数据转化为一个好的答案。人类擅长通过10次观察作出非常有创意的猜测。

来源网址: [We’re Entering Uncharted Territory for Math](https://www.theatlantic.com/technology/archive/2024/10/terence-tao-ai-interview/680153/)